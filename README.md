# Neuroscience

## Learning action responses

* ["Brain" In A Dish Acts As Autopilot, Living Computer](https://news.ufl.edu/archive/2004/10/uf-scientist-brain-in-a-dish-acts-as-autopilot-living-computer.html)

> The “brain” — a collection of 25,000 living neurons, or nerve cells, taken from a rat’s brain and cultured inside a glass dish ...
>
> When DeMarse first puts the neurons in the dish, they look like little more than grains of sand sprinkled in water. However, individual neurons soon begin to extend microscopic lines toward each other, making connections that represent neural processes. “You see one extend a process, pull it back, extend it out – and it may do that a couple of times, just sampling who’s next to it, until over time the connectivity starts to establish itself,” he said. “(The brain is) getting its network to the point where it’s a live computation device.”
>
> “Initially when we hook up this brain to a flight simulator, it doesn’t know how to control the aircraft,” DeMarse said. “So you hook it up and the aircraft simply drifts randomly. And as the data comes in, it slowly modifies the (neural) network so over time, the network gradually learns to fly the aircraft.”

**personal notes**: This experiment could provide key insight into how a "brain" (a network of biological neurons) may learn what actions to send without the need for reward. The input/prediction/output feedback loop would try to minimize prediction error, as is the intrinsic function of neurons and their synaptic processes per Hebbian learning and Spike-Time-Dependent-Plasticity. As output (i.e. actions) have an effect on the environment, the proper action selection choice may help minimize future prediction errors. In essence, this relates to proprioception, having a model of where one is in the world and updating this model based on actions to better predict future stimuli.
